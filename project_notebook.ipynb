{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "dc": {
          "key": "3"
        },
        "id": "rh-KVKVkdhAF",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "html_tables = {}\n",
        "\n",
        "# For every table in the datasets folder...\n",
        "for table_name in os.listdir('datasets'):\n",
        "    #this is the path to the file. Don't touch!\n",
        "    table_path = f'datasets/{table_name}'\n",
        "    # Open as a python file in read-only mode\n",
        "    table_file = open(table_path, 'r')\n",
        "    # Read the contents of the file into 'html'\n",
        "    html = BeautifulSoup(table_file)\n",
        "    # Find 'news-table' in the Soup and load it into 'html_table'\n",
        "    html_table = html.find(id=\"news-table\")\n",
        "    # Add the table to our dictionary\n",
        "    html_tables[table_name] = html_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "colab_type": "code",
        "dc": {
          "key": "10"
        },
        "id": "FGmxVHKndhAK",
        "outputId": "44af2718-732c-452d-85cb-6458adbe11e0",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# Read one single day of headlines \n",
        "tsla = html_tables['tsla_22sep.html']\n",
        "# Get all the table rows tagged in HTML with <tr> into 'tesla_tr'\n",
        "tsla_tr = tsla.findAll('tr')\n",
        "\n",
        "# For each row...\n",
        "for i, table_row in enumerate(tsla_tr):\n",
        "    # Read the text of the element 'a' into 'link_text'\n",
        "    link_text = table_row.a.get_text()\n",
        "    # Read the text of the element 'td' into 'data_text'\n",
        "    data_text = table_row.td.get_text()\n",
        "    # Print the count\n",
        "    print(f'File number {i+1}:')\n",
        "    # Print the contents of 'link_text' and 'data_text' \n",
        "    print(link_text)\n",
        "    print(data_text)\n",
        "    # The following exits the loop after four rows to prevent spamming the notebook, do not touch\n",
        "    if i == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "dc": {
          "key": "17"
        },
        "id": "LeL2F_eXdhAP",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# Hold the parsed news into a list\n",
        "parsed_news = []\n",
        "# Iterate through the news\n",
        "for file_name, news_table in html_tables.items():\n",
        "    # Iterate through all tr tags in 'news_table'\n",
        "    for x in news_table.findAll('tr'):\n",
        "        # Read the text from the tr tag into text\n",
        "        text = x.get_text() \n",
        "        headline = x.a.get_text()\n",
        "        # Split the text in the td tag into a list \n",
        "        date_scrape = x.td.text.split()\n",
        "        # If the length of 'date_scrape' is 1, load 'time' as the only element\n",
        "        # If not, load 'date' as the 1st element and 'time' as the second\n",
        "        if  len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
        "        ticker = file_name.split('_')[0]\n",
        "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
        "        parsed_news.append([ticker, date, time, headline])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "dc": {
          "key": "24"
        },
        "id": "PJwlFArTdhAT",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# NLTK VADER for sentiment analysis\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# New words and values\n",
        "new_words = {\n",
        "    'crushes': 10, \n",
        "    'beats': 5,\n",
        "    'misses': -5,\n",
        "    'trouble': -10,\n",
        "    'falls': -100,\n",
        "}\n",
        "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Update the lexicon\n",
        "vader.lexicon.update(new_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "dc": {
          "key": "31"
        },
        "id": "fGrafpZ3dhAW",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Use these column names\n",
        "columns = ['ticker', 'date', 'time', 'headline']\n",
        "# Convert the list of lists into a DataFrame\n",
        "scored_news = pd.DataFrame(parsed_news, columns=columns)\n",
        "# Iterate through the headlines and get the polarity scores\n",
        "scores = [vader.polarity_scores(headline) for headline in scored_news.headline.values]\n",
        "# Convert the list of dicts into a DataFrame\n",
        "scores_df = pd.DataFrame(scores)\n",
        "# Join the DataFrames\n",
        "scored_news = pd.concat([scored_news, scores_df], axis=1)\n",
        "# Convert the date column from string to datetime\n",
        "scored_news['date'] = pd.to_datetime(scored_news.date).dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "colab_type": "code",
        "dc": {
          "key": "38"
        },
        "id": "Me34EDc9dhAc",
        "outputId": "1c641d7c-ce59-4317-98ce-b4304b299f5c",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Group by date and ticker columns from scored_news and calculate the mean\n",
        "mean_c = scored_news.groupby(['date', 'ticker']).mean()\n",
        "# Unstack the column ticker\n",
        "mean_c = mean_c.unstack(level=1)\n",
        "# Get the cross-section of compound in the 'columns' axis\n",
        "mean_c = mean_c.xs('compound', axis=1)\n",
        "# Plot a bar chart with pandas\n",
        "# ... YOUR CODE FOR TASK 6 ...\n",
        "mean_c.plot.bar()\n",
        "plt.savefig('sentiment.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "dc": {
          "key": "45"
        },
        "id": "Klfj7AJPdhAg",
        "outputId": "1a476bda-6f75-4cc4-ece8-f964b7af2823",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# Count the number of headlines in scored_news (store as integer)\n",
        "num_news_before = scored_news['headline'].count()\n",
        "# Drop duplicates based on ticker and headline\n",
        "scored_news_clean = scored_news.drop_duplicates(subset=['ticker', 'headline'])\n",
        "# Count number of headlines after dropping duplicates\n",
        "num_news_after = scored_news_clean['headline'].count()\n",
        "# Print before and after numbers to get an idea of how we did \n",
        "f\"Before we had {num_news_before} headlines, now we have {num_news_after}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "dc": {
          "key": "52"
        },
        "id": "II2HfD_SdhAj",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "# Set the index to ticker and date\n",
        "single_day = scored_news_clean.set_index(['ticker', 'date'])\n",
        "# Cross-section the fb row\n",
        "single_day = single_day.loc['fb']\n",
        "# Convert index to datetime type\n",
        "single_day.index = pd.to_datetime(single_day.index)\n",
        "# Select the 4th of January of 2019\n",
        "single_day = single_day.loc['2019-01-04']\n",
        "# Convert the datetime string to just the time\n",
        "single_day['time'] = pd.to_datetime(single_day['time'])\n",
        "single_day['time'] = single_day.time.dt.time \n",
        "# Set the index to time\n",
        "single_day = single_day.set_index('time')\n",
        "# Sort it\n",
        "single_day = single_day.sort_index(ascending=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "colab_type": "code",
        "dc": {
          "key": "59"
        },
        "id": "EojOxtI2dhAm",
        "outputId": "3107457a-5540-4654-fdc3-413ea27c67f2",
        "tags": [
          "sample_code"
        ]
      },
      "outputs": [],
      "source": [
        "TITLE = \"Positive, negative and neutral sentiment for FB on 2019-09-03\"\n",
        "COLORS = [\"red\", \"orange\", \"blue\"]\n",
        "# Drop the columns that aren't useful for the plot\n",
        "plot_day = single_day.drop(['headline', 'compound'], axis=1)\n",
        "# Change the column names to 'negative', 'positive', and 'neutral'\n",
        "plot_day.columns = ['negative', 'positive', 'neutral']\n",
        "# Plot a stacked bar chart\n",
        "# ... YOUR CODE FOR TASK 9 :-) ...\n",
        "plot_day.plot(kind='bar', stacked=True)\n",
        "plt.savefig('finalplot.png', bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
